{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install minisom from jupyter notebook cell\n",
    "# !pip install minisom\n",
    "\n",
    "# OR \n",
    "# install from Terminal/Anaconda Prompt \n",
    "# (Don't forget to restart Anaconda Navigator)\n",
    "# pip install minisom\n",
    "\n",
    "\n",
    "# Source and documentation:\n",
    "# https://github.com/JustGlowing/minisom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from minisom import MiniSom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Matplotlib functions to create MiniSOM visualizations\n",
    "\n",
    "from matplotlib.patches import RegularPolygon, Ellipse\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import cm, colorbar\n",
    "from matplotlib import colors as mpl_colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import __version__ as mplver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recommended version at least 3.7.0 or greater\n",
    "print(\"matplotlib version is:\" , mplver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('..', 'data', 'data_preprocessed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting feature names into groups\n",
    "# Remember which metric_features we decided to keep?\n",
    "metric_features = ['income',\n",
    " 'frq',\n",
    " 'rcn',\n",
    " 'clothes',\n",
    " 'kitchen',\n",
    " 'small_appliances',\n",
    " 'toys',\n",
    " 'house_keeping',\n",
    " 'per_net_purchase',\n",
    " 'spent_online']\n",
    "\n",
    "non_metric_features = df.columns[df.columns.str.startswith('oh_')].tolist() # CODE HERE\n",
    "pc_features = df.columns[df.columns.str.startswith('PC')].tolist()  # CODE HERE\n",
    "\n",
    "unused_features = [i for i in df.columns if i not in (metric_features+non_metric_features+pc_features) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('metric_features:', metric_features)\n",
    "print('\\nnon_metric_features:', non_metric_features)\n",
    "print('\\nunused_features:', unused_features)\n",
    "print('\\npc_features:', pc_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-organizing maps\n",
    "What is a SOM? How does it work? What is it used for?\n",
    "\n",
    "The SOM objective is to adjust the units to the data in the input space, so that the\n",
    "network is (as best as possible) representative of the training dataset.\n",
    "\n",
    "### How is it computed?\n",
    "### Important concepts:\n",
    "- Units and observations\n",
    "- BMU\n",
    "- Neighborhood function\n",
    "- Input and Output space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Video:**\n",
    "\n",
    "(May be a good idea to mute the video before playing)\n",
    "\n",
    "https://www.youtube.com/watch?v=k7DK5fnJH94\n",
    "\n",
    "https://www.youtube.com/watch?v=zyYZuAQZWTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics:\n",
    "- Grid shape needs to be set a priori\n",
    "- Results depend on the initialization (even tough it can be quite robust to it)\n",
    "- Fitting a SOM can be computationally expensive\n",
    "- Capable of finding the global optimum (theoretically - if the LR -> 0)\n",
    "- Visualization tool for high-dimensional data\n",
    "\n",
    "### Additional analyses/tutorials\n",
    "- [Air Flights](https://github.com/sevamoo/SOMPY/blob/master/sompy/examples/AirFlights_hexagonal_grid.ipynb)\n",
    "- [Visualizations on toy datasets](https://gist.github.com/sevamoo/035c56e7428318dd3065013625f12a11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example\n",
    "\n",
    "Based on https://github.com/JustGlowing/minisom/blob/master/examples/ColorSpaceMapping.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def tidy_ax(ax, major_ticks, minor_ticks, minor_lim=None):\n",
    "\n",
    "    ax.set_xticks(major_ticks-.5)\n",
    "    ax.set_xticks(minor_ticks-.5, minor=True)\n",
    "\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    ax.grid(which='both', alpha=0.5, color='white', linewidth=1)\n",
    "\n",
    "    ax.tick_params(axis='both', which='both', direction=\"in\", width=0, length=0)\n",
    "\n",
    "    if minor_lim == None:\n",
    "        minor_lim = major_ticks.max()\n",
    "\n",
    "    ax.set_yticks(major_ticks[major_ticks<minor_lim]-.5, )\n",
    "    ax.set_yticks(minor_ticks[minor_ticks<minor_lim]-.5, minor=True)\n",
    "    \n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Number Generator from numpy\n",
    "rng = np.random.default_rng(638468314)\n",
    "\n",
    "# Generate random colors using RGB code\n",
    "random_colors = rng.uniform(0,1,(100,3)).round(2)\n",
    "random_colors_df = pd.DataFrame(random_colors, columns=[\"R\",\"G\",\"B\"])\n",
    "random_colors_df.reset_index(inplace=True)\n",
    "\n",
    "# Preview randomly generated colors\n",
    "sns.color_palette(random_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MiniSom\n",
    "\n",
    "colors_dims = (30, 40)\n",
    "\n",
    "som_colors = MiniSom(*colors_dims,          # Size of SOM grid\n",
    "                     3,                     # Number of features\n",
    "                     sigma=3.,              # Neighborhood radius\n",
    "                     learning_rate=2.5,     # Learning rate\n",
    "                     random_seed=42,        # Random seed\n",
    "                     neighborhood_function='gaussian' # Neighborhood radius function\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplot_mosaic([\n",
    "                            ['two', 'two'],\n",
    "                            ['left', 'right'],\n",
    "                            ],\n",
    "                               figsize=(16,8), \n",
    "                         height_ratios=[1,19],\n",
    "                         constrained_layout=True)\n",
    "\n",
    "################################\n",
    "## Plot random color (input data)\n",
    "################################\n",
    "\n",
    "ax = axes['two']\n",
    "\n",
    "sns.scatterplot(random_colors_df, x='index', y=0, \n",
    "                palette=random_colors.tolist(), hue='index', \n",
    "                ax=ax, legend=False, s=100, edgecolor='white')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.margins(0.01)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_title(\"Original Random Color Values\")\n",
    "\n",
    "################################\n",
    "## Plot random initialized weights\n",
    "################################\n",
    "\n",
    "\n",
    "major_ticks = np.arange(0, 41, 5)\n",
    "minor_ticks = np.arange(0, 41, 1)\n",
    "\n",
    "ax = axes['left']\n",
    "\n",
    "ax.imshow(abs(som_colors.get_weights()), interpolation='none', origin=\"lower\", alpha=.75)\n",
    "\n",
    "ax = tidy_ax(ax, major_ticks, minor_ticks, 30)\n",
    "\n",
    "ax.set_title(\"SOM Random Weights\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "## Plot trained SOM\n",
    "################################\n",
    "\n",
    "som_colors.train(random_colors, 500, random_order=True, verbose=True)\n",
    "\n",
    "ax = axes['right']\n",
    "\n",
    "ax.imshow(abs(som_colors.get_weights()), interpolation='none', origin=\"lower\", alpha=.75)\n",
    "\n",
    "for i in random_colors:\n",
    "    yx = som_colors.winner(i)\n",
    "\n",
    "    ax.scatter(yx[1], yx[0], c=[i], edgecolors='white', alpha=1, s=100, linewidth=2)\n",
    "    \n",
    "\n",
    "\n",
    "ax = tidy_ax(ax, major_ticks, minor_ticks, 30)\n",
    "ax.set_title(\"SOM After Training\")\n",
    "fig.savefig(\"./../figures/clustering/som_rgb.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(14,8), \n",
    "                        gridspec_kw={'hspace': .15},\n",
    "                         constrained_layout=True,\n",
    "                         dpi=120)\n",
    "\n",
    "colors_dims = (30, 40)\n",
    "major_ticks = np.arange(0, 41, 5)\n",
    "minor_ticks = np.arange(0, 41, 1)\n",
    "\n",
    "################################\n",
    "## Plot random initialized weights\n",
    "################################\n",
    "\n",
    "\n",
    "# Initialize MiniSom\n",
    "\n",
    "som_c = MiniSom(*colors_dims,          # Size of SOM grid\n",
    "                 3,                     # Number of features\n",
    "                 sigma=3.,              # Neighborhood radius\n",
    "                 learning_rate=2.5,     # Learning rate\n",
    "                 random_seed=42,        # Random seed\n",
    "                 neighborhood_function='gaussian' # Neighborhood radius function\n",
    "                 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax = axes[0][0]\n",
    "\n",
    "ax.imshow(abs(som_c.get_weights()), interpolation='none', origin=\"lower\")\n",
    "ax = tidy_ax(ax, major_ticks, minor_ticks, 30)\n",
    "qe = np.round(som_c.quantization_error(random_colors),3)\n",
    "te = np.round(som_c.topographic_error(random_colors),3)\n",
    "ax.set_title(\"SOM Random Weights\\nQE:{} TE:{}\".format(qe, te))\n",
    "\n",
    "\n",
    "################################\n",
    "## Plot trained SOM\n",
    "################################\n",
    "\n",
    "ax = axes[0][1]\n",
    "\n",
    "som_c.train(random_colors, 500, random_order=True, verbose=False)\n",
    "ax.imshow(abs(som_c.get_weights()), interpolation='none', origin=\"lower\", alpha=.75)\n",
    "ax = tidy_ax(ax, major_ticks, minor_ticks, 30)\n",
    "qe = np.round(som_c.quantization_error(random_colors),3)\n",
    "te = np.round(som_c.topographic_error(random_colors),3)\n",
    "ax.set_title(\"SOM Trained 500 iters, sigma=3, LR=2.5\\nQE:{} TE:{}\".format(qe, te))\n",
    "\n",
    "ax = axes[0][2]\n",
    "\n",
    "som_c = MiniSom(*colors_dims,          # Size of SOM grid\n",
    "                 3,                     # Number of features\n",
    "                 sigma=3.,              # Neighborhood radius\n",
    "                 learning_rate=2.5,     # Learning rate\n",
    "                 random_seed=42,        # Random seed\n",
    "                 neighborhood_function='gaussian' # Neighborhood radius function\n",
    "                 )\n",
    "som_c.train(random_colors, len(random_colors), random_order=True, verbose=False)\n",
    "ax.imshow(abs(som_c.get_weights()), interpolation='none', origin=\"lower\", alpha=.75)\n",
    "ax = tidy_ax(ax, major_ticks, minor_ticks, 30)\n",
    "qe = np.round(som_c.quantization_error(random_colors),3)\n",
    "te = np.round(som_c.topographic_error(random_colors),3)\n",
    "ax.set_title(\"SOM Trained N iters, sigma=3, LR=2.5\\nQE:{} TE:{}\".format(qe, te))\n",
    "\n",
    "################################\n",
    "## Plot trained SOM\n",
    "################################\n",
    "\n",
    "ax = axes[1][0]\n",
    "\n",
    "som_c = MiniSom(*colors_dims,          # Size of SOM grid\n",
    "                 3,                     # Number of features\n",
    "                 sigma=1.,              # Neighborhood radius\n",
    "                 learning_rate=2.5,     # Learning rate\n",
    "                 random_seed=42,        # Random seed\n",
    "                 neighborhood_function='gaussian' # Neighborhood radius function\n",
    "                 )\n",
    "som_c.train(random_colors, 500, random_order=True, verbose=False)\n",
    "ax.imshow(abs(som_c.get_weights()), interpolation='none', origin=\"lower\", alpha=.75)\n",
    "ax = tidy_ax(ax, major_ticks, minor_ticks, 30)\n",
    "qe = np.round(som_c.quantization_error(random_colors),3)\n",
    "te = np.round(som_c.topographic_error(random_colors),3)\n",
    "ax.set_title(\"SOM Trained 500 iters, sigma=1, LR=2.5\\nQE:{} TE:{}\".format(qe, te))\n",
    "\n",
    "################################\n",
    "## Plot trained SOM\n",
    "################################\n",
    "\n",
    "ax = axes[1][1]\n",
    "\n",
    "som_c = MiniSom(*colors_dims,          # Size of SOM grid\n",
    "                 3,                     # Number of features\n",
    "                 sigma=3.,              # Neighborhood radius\n",
    "                 learning_rate=1.5,     # Learning rate\n",
    "                 random_seed=42,        # Random seed\n",
    "                 neighborhood_function='gaussian' # Neighborhood radius function\n",
    "                 )\n",
    "som_c.train(random_colors, 500, random_order=True, verbose=False)\n",
    "ax.imshow(abs(som_c.get_weights()), interpolation='none', origin=\"lower\", alpha=.75)\n",
    "ax = tidy_ax(ax, major_ticks, minor_ticks, 30)\n",
    "qe = np.round(som_c.quantization_error(random_colors),3)\n",
    "te = np.round(som_c.topographic_error(random_colors),3)\n",
    "ax.set_title(\"SOM Trained 500 iters, sigma=3, LR=1.5\\nQE:{} TE:{}\".format(qe, te))\n",
    "\n",
    "################################\n",
    "## Plot trained SOM\n",
    "################################\n",
    "\n",
    "ax = axes[1][2]\n",
    "\n",
    "som_c = MiniSom(*colors_dims,          # Size of SOM grid\n",
    "                 3,                     # Number of features\n",
    "                 sigma=3.,              # Neighborhood radius\n",
    "                 learning_rate=2.5,     # Learning rate\n",
    "                 random_seed=42,        # Random seed\n",
    "                 neighborhood_function='gaussian' # Neighborhood radius function\n",
    "                 )\n",
    "som_c.train(random_colors, 2, random_order=True, verbose=False, use_epochs=True)\n",
    "ax.imshow(abs(som_c.get_weights()), interpolation='none', origin=\"lower\", alpha=.75)\n",
    "ax = tidy_ax(ax, major_ticks, minor_ticks, 30)\n",
    "\n",
    "qe = np.round(som_c.quantization_error(random_colors),3)\n",
    "te = np.round(som_c.topographic_error(random_colors),3)\n",
    "ax.set_title(\"SOM Batch Trained 2 iters/sample, sigma=3, LR=2.5\\nQE:{} TE:{}\".format(qe, te))\n",
    "\n",
    "# fig.savefig(\"./../figures/clustering/som_demo.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to apply Self-Organizing Maps?\n",
    "\n",
    "The training of a SOM is **more effective** if it is done in two phases: the unfolding phase, and the fine-tuning phase. \n",
    "\n",
    "In the **unfolding phase** the objective is to **spread the units** in the region of the input space where the data patterns are located. In this phase the neighbourhood function should have a large initial radius so that all units have high mobility and the map can quickly cover the input space.\n",
    "\n",
    "The **fine tuning phase**, as the name implies, is the process of small adjustments in order to **reduce the quantization error**, and centre the units in the areas where the density of patterns is highest. Usually, in this phase the learning rate and the neighbourhood radius are smaller than the ones used in the unfolding phase. As these two parameters are smaller, the map will need more time to adjust its weights and that is why the number of iterations or epochs is normally higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- Train a SOM with a 10x10 grid, random initialization, gaussian neighborhood function and hexagonal topology/lattice\n",
    "- Set training of 100 iterations\n",
    "\n",
    "\n",
    "Documentation of `train` method:\n",
    "\n",
    "https://github.com/JustGlowing/minisom/blob/master/minisom.py#L467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 0\n",
    "N = 0\n",
    "neighborhood_function = None \n",
    "topology = None \n",
    "n_feats = len(metric_features)\n",
    "learning_rate = None\n",
    "\n",
    "\n",
    "som_data = df[metric_features].values\n",
    "\n",
    "sm = MiniSom(M, N,              # 10x10 map size\n",
    "             n_feats,           # Number of the elements of the vectors in input.\n",
    "             learning_rate=learning_rate, \n",
    "             topology=topology, \n",
    "             neighborhood_function=neighborhood_function, \n",
    "             activation_distance='euclidean',\n",
    "             random_seed=42\n",
    "             )\n",
    "\n",
    "# Initializes the weights of the SOM picking random samples from data.\n",
    "sm.random_weights_init(som_data) \n",
    "\n",
    "\n",
    "print(\"Before training:\")\n",
    "print(\"QE\", np.round(sm.quantization_error(som_data),4))\n",
    "print(\"TE\", np.round(sm.topographic_error(som_data),4))\n",
    "\n",
    "\n",
    "\n",
    "# Trains the SOM using all the vectors in data sequentially\n",
    "# minisom does not distinguish between unfolding and fine tuning phase;\n",
    "\n",
    "sm.train_batch(som_data, 20000)\n",
    "\n",
    "print(\"After training:\")\n",
    "print(\"QE\", np.round(sm.quantization_error(som_data),4))\n",
    "print(\"TE\", np.round(sm.topographic_error(som_data),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data with SOMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component planes\n",
    "What do they represent? What kinds of information do they contain?\n",
    "\n",
    "Analyse these plots from the following perspectives:\n",
    "- Feature importance\n",
    "- Feature correlation (both globally and locally)\n",
    "- Data distribution\n",
    "- Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are these weights?\n",
    "weights = sm.get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hexagons(som,              # Trained SOM model \n",
    "                  sf,               # matplotlib figure object\n",
    "                  colornorm,        # colornorm\n",
    "                  matrix_vals,      # SOM weights or\n",
    "                  label=\"\",         # title for figure\n",
    "                  cmap=cm.Grays,    # colormap to use\n",
    "                  annot=False       \n",
    "                  ):\n",
    "\n",
    "    \n",
    "    axs = sf.subplots(1,1)\n",
    "    \n",
    "    for i in range(matrix_vals.shape[0]):\n",
    "        for j in range(matrix_vals.shape[1]):\n",
    "\n",
    "            wx, wy = som.convert_map_to_euclidean((i,j)) \n",
    "\n",
    "            hex = RegularPolygon((wx, wy), \n",
    "                                numVertices=6, \n",
    "                                radius= np.sqrt(1/3),\n",
    "                                facecolor=cmap(colornorm(matrix_vals[i, j])), \n",
    "                                alpha=1, \n",
    "                                edgecolor='white',\n",
    "                                linewidth=.5)\n",
    "            axs.add_patch(hex)\n",
    "            if annot==True:\n",
    "                annot_val = np.round(matrix_vals[i,j],2)\n",
    "                if int(annot_val) == annot_val:\n",
    "                    annot_val = int(annot_val)\n",
    "                axs.text(wx,wy, annot_val, \n",
    "                        ha='center', va='center', \n",
    "                        fontsize='x-small')\n",
    "\n",
    "\n",
    "    ## Remove axes for hex plot\n",
    "    axs.margins(.05)\n",
    "    axs.set_aspect('equal')\n",
    "    axs.axis(\"off\")\n",
    "    axs.set_title(label)\n",
    "\n",
    "    \n",
    "\n",
    "    # ## Add colorbar\n",
    "    divider = make_axes_locatable(axs)\n",
    "    ax_cb = divider.append_axes(\"right\", size=\"5%\", pad=\"0%\")\n",
    "\n",
    "    ## Create a Mappable object\n",
    "    cmap_sm = plt.cm.ScalarMappable(cmap=cmap, norm=colornorm)\n",
    "    cmap_sm.set_array([])\n",
    "\n",
    "    ## Create custom colorbar \n",
    "    cb1 = colorbar.Colorbar(ax_cb,\n",
    "                            orientation='vertical', \n",
    "                            alpha=1,\n",
    "                            mappable=cmap_sm\n",
    "                            )\n",
    "    cb1.ax.get_yaxis().labelpad = 6\n",
    "\n",
    "    # Add colorbar to plot\n",
    "    sf.add_axes(ax_cb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return sf \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Plot Component Planes\n",
    "##############################\n",
    "\n",
    "figsize=(10,7)\n",
    "fig = plt.figure(figsize=figsize, constrained_layout=True, dpi=128, )\n",
    "\n",
    "subfigs = fig.subfigures(3,4,wspace=.15)\n",
    "\n",
    "colornorm = mpl_colors.Normalize(vmin=np.min(weights), vmax=np.max(weights))\n",
    "\n",
    "for cpi, sf in zip(range(len(metric_features)), subfigs.flatten()):\n",
    "    \n",
    "    matrix_vals = weights[:,:,cpi]\n",
    "    vext = np.max(np.abs([np.min(matrix_vals), np.max(matrix_vals)]))\n",
    "    colornorm = mpl_colors.Normalize(vmin=np.min(matrix_vals), vmax=np.max(matrix_vals))\n",
    "    # colornorm = mpl_colors.CenteredNorm(vcenter=0, halfrange=vext)\n",
    "\n",
    "\n",
    "    sf = plot_hexagons(sm, sf, \n",
    "                    colornorm,\n",
    "                    matrix_vals,\n",
    "                    label=metric_features[cpi],\n",
    "                    cmap=cm.coolwarm,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-matrix\n",
    "Encode each neuron in the output space with the **average distance** to its neighbors in the input space.\n",
    "\n",
    "Analyse these plots from the following perspectives:\n",
    "- Clusters of units\n",
    "- Potential outliers (units which are very distant from its neighbors and have low frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umatrix = sm.distance_map(scaling='mean')\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "colornorm = mpl_colors.Normalize(vmin=np.min(umatrix), vmax=np.max(umatrix))\n",
    "\n",
    "fig = plot_hexagons(sm, fig, \n",
    "                    colornorm,\n",
    "                    umatrix,\n",
    "                    label=\"U-matrix\",\n",
    "                    cmap=cm.RdYlBu_r,\n",
    "                    annot=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flip and rotate to match plot\n",
    "print(np.flip(np.round(umatrix,2), axis=1).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hit-map\n",
    "Show the **frequency** of each Unit in the output map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitsmatrix = sm.activation_response(df[metric_features].values)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "colornorm = mpl_colors.Normalize(vmin=0, vmax=np.max(hitsmatrix))\n",
    "\n",
    "fig = plot_hexagons(sm, fig, \n",
    "                    colornorm,\n",
    "                    hitsmatrix,\n",
    "                    label=\"SOM Hits Map\",\n",
    "                    cmap=cm.Greens,\n",
    "                    annot=True\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Values of HITS:\n",
    "## Flip and rotate to match plot\n",
    "np.flip(np.round(hitsmatrix,2), axis=1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.quantization_error(df[metric_features].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with SOMs: K-means SOM vs Emergent SOM\n",
    "- In **k-means SOM**, the *number of units should be equal to the expected number of clusters*, and thus each cluster should be represented by a single unit. \n",
    "- In **emergent SOM**, a very *large number of units is used*. These very large SOM allow for very clear U-Matrices and are useful for detecting quite clearly the underlying structure of the data. This technique can be **used together with other clustering algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- Train a SOM with a 50x50 grid, random initialization, gaussian neighborhood function and hexagonal topology/lattice\n",
    "- Set an unfolding phase and a fine tuning phase of 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# M = 50\n",
    "# N = 50\n",
    "\n",
    "M = 20 # 50 takes too long to run\n",
    "N = 30 # \n",
    "neighborhood_function = 'gaussian' \n",
    "topology = 'hexagonal' \n",
    "n_feats = len(metric_features)\n",
    "learning_rate = .7\n",
    "\n",
    "\n",
    "som_data = df[metric_features].values\n",
    "\n",
    "sm = MiniSom(M, N,              # 10x10 map size\n",
    "             n_feats,           # Number of the elements of the vectors in input.\n",
    "             learning_rate=learning_rate, \n",
    "             topology=topology, \n",
    "             neighborhood_function=neighborhood_function, \n",
    "             activation_distance='euclidean',\n",
    "             random_seed=42\n",
    "             )\n",
    "\n",
    "\n",
    "som_data = df[metric_features].values\n",
    "# Initializes the weights of the SOM picking random samples from data.\n",
    "sm.random_weights_init(som_data) \n",
    "\n",
    "print(np.round(sm.quantization_error(som_data),4), \"Starting QE\")\n",
    "print(np.round(sm.topographic_error(som_data),4), \"Starting TE\")\n",
    "\n",
    "\n",
    "# Trains the SOM using all the vectors in data sequentially\n",
    "# minisom does not distinguish between unfolding and fine tuning phase;\n",
    "\n",
    "sm.train_batch(som_data, 500000)\n",
    "print(np.round(sm.quantization_error(som_data),4),\"Ending QE\")\n",
    "print(np.round(sm.topographic_error(som_data),4),\"Ending TE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Plot Component Planes\n",
    "##############################\n",
    "\n",
    "weights = sm.get_weights()\n",
    "\n",
    "figsize=(10,7)\n",
    "fig = plt.figure(figsize=figsize, constrained_layout=True, dpi=128, )\n",
    "\n",
    "subfigs = fig.subfigures(3,4,wspace=.15)\n",
    "\n",
    "colornorm = mpl_colors.Normalize(vmin=np.min(weights), vmax=np.max(weights))\n",
    "\n",
    "for cpi, sf in zip(range(len(metric_features)), subfigs.flatten()):\n",
    "    \n",
    "    matrix_vals = weights[:,:,cpi]\n",
    "    vext = np.max(np.abs([np.min(matrix_vals), np.max(matrix_vals)]))\n",
    "    colornorm = mpl_colors.Normalize(vmin=np.min(matrix_vals), vmax=np.max(matrix_vals))\n",
    "\n",
    "\n",
    "    sf = plot_hexagons(sm, sf, \n",
    "                    colornorm,\n",
    "                    matrix_vals,\n",
    "                    label=metric_features[cpi],\n",
    "                    cmap=cm.coolwarm,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umatrix = sm.distance_map(scaling='mean')\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "colornorm = mpl_colors.Normalize(vmin=np.min(umatrix), vmax=np.max(umatrix))\n",
    "\n",
    "fig = plot_hexagons(sm, fig, \n",
    "                    colornorm,\n",
    "                    umatrix,\n",
    "                    label=\"U-matrix\",\n",
    "                    cmap=cm.RdYlBu_r,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitsmatrix = sm.activation_response(df[metric_features].values)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "colornorm = mpl_colors.Normalize(vmin=0, vmax=np.max(hitsmatrix))\n",
    "\n",
    "fig = plot_hexagons(sm, fig, \n",
    "                    colornorm,\n",
    "                    hitsmatrix,\n",
    "                    label=\"SOM Hits Map\",\n",
    "                    cmap=cm.Greens,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a better idea of how the input space look like in terms of distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means on top of SOM units\n",
    "- Define number of clusters to retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "# Do the Inertia plot here (check last class' notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_flat = sm.get_weights().reshape((M*N),len(metric_features))\n",
    "weights_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Means clustering on top of the MxN units (sm.get_node_vectors() output)\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', n_init=20, random_state=42)\n",
    "nodeclus_labels = kmeans.fit_predict(weights_flat)\n",
    "nodeclus_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_matrix = nodeclus_labels.reshape((M,N))\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "colornorm = mpl_colors.Normalize(vmin=0, vmax=np.max(kmeans_matrix))\n",
    "\n",
    "fig = plot_hexagons(sm, fig, \n",
    "                    colornorm,\n",
    "                    kmeans_matrix,\n",
    "                    label=\"SOM K-Means\",\n",
    "                    cmap=cm.Spectral,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering on top of SOM units\n",
    "- Define best linkage method\n",
    "- Define number of clusters to retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "# Do the R² plot here and the Dendrogram (check last class' notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Hierarchical clustering on top of the MxN units \n",
    "\n",
    "hierclust = AgglomerativeClustering(n_clusters=4, linkage='ward')\n",
    "nodeclus_labels = hierclust.fit_predict(weights_flat)\n",
    "hclust_matrix = nodeclus_labels.reshape((M,N))\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "colornorm = mpl_colors.Normalize(vmin=0, vmax=np.max(hclust_matrix))\n",
    "\n",
    "fig = plot_hexagons(sm, fig, \n",
    "                    colornorm,\n",
    "                    hclust_matrix,\n",
    "                    label=\"SOM Hierarchical\",\n",
    "                    cmap=cm.Spectral,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final SOM Clustering solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the nodes and and respective clusters\n",
    "nodes = weights_flat\n",
    "\n",
    "df_nodes = pd.DataFrame(nodes, columns=metric_features)\n",
    "df_nodes['label'] = nodeclus_labels\n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This gets BMU coordinates, e.g. (4,4) for each data point\n",
    "bmu_index = np.array([sm.winner(x) for x in df[metric_features].values])\n",
    "\n",
    "print(bmu_index.shape)\n",
    "\n",
    "bmu_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## This gets the cluster label from hclust_matrix, i.e.\n",
    "## if data row 0 has BMU at (37, 28) \n",
    "## it will get the label associated to node (37,28) using label associated to hclust_matrix[37,28] above\n",
    "\n",
    "som_final_labels = [hclust_matrix[i[0]][i[1]] for i in bmu_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([\n",
    "                df,\n",
    "                pd.Series(som_final_labels, name='label', index=df.index)\n",
    "            ], axis=1\n",
    "            )\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the final clusters\n",
    "df_final[metric_features+['label']].groupby('label').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the appropriateness of our solution\n",
    "### R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using R²\n",
    "def get_ss(df):\n",
    "    ss = np.sum(df.var() * (df.count() - 1))\n",
    "    return ss  # return sum of sum of squares of each df variable\n",
    "\n",
    "sst = get_ss(df_final[metric_features])  # get total sum of squares\n",
    "ssw_labels = df_final[metric_features + [\"label\"]].groupby(by='label').apply(get_ss)  # compute ssw for each cluster labels\n",
    "ssb = sst - np.sum(ssw_labels)  # remember: SST = SSW + SSB\n",
    "r2 = ssb / sst\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization error:\n",
    "The quantization error is given by the average distance between a unit and the data points mapped to it i.e. all the input data points that share it as BMU.\n",
    "\n",
    "$$q_e = \\frac{\\sum_{i=0}^{N_e}||x_i - w_e||}{N_e}$$\n",
    "\n",
    "$$Q = \\frac{\\sum_{e=0}^Eq_e}{E}$$\n",
    ", where:\n",
    "\n",
    "$Q$ is the overall quantization error of SOM,\n",
    "\n",
    "$q_e$ is the quantization error for unit $e$,\n",
    "\n",
    "$x_i$ is a data point/ observation,\n",
    "\n",
    "$w_e$ is the unit $e$ representation in the input space,\n",
    "\n",
    "$N_e$ is number of data points mapped to unit $e$,\n",
    "\n",
    "$E$ is the number of units in the SOM grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.quantization_error(som_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topographic error:\n",
    "\n",
    "> \n",
    "> Returns the topographic error computed by finding\n",
    "> the best-matching and second-best-matching neuron in the map\n",
    "> for each input and then evaluating the positions.\n",
    ">\n",
    "> A sample for which these two nodes are not adjacent counts as\n",
    "> an error. The topographic error is given by the\n",
    "> the total number of errors divided by the total of samples.\n",
    "> \n",
    "> If the topographic error is 0, no error occurred.\n",
    "> If 1, the topology was not preserved for any of the samples\n",
    "> \n",
    "\n",
    "https://github.com/JustGlowing/minisom/blob/master/minisom.py#L650\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.topographic_error(som_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
